{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59a7a6-b4a9-4878-b9ab-9abf32f00610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "all_file_paths = [f\"modified_data_Tip_Position_-2mm/corrected_2000RPMfeedspeed30mmmin_IL_bone{i}.csv\" for i in range(1, 269)]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_file_paths)\n",
    "\n",
    "total_files = len(all_file_paths)\n",
    "num_train = int(total_files * 0.6)\n",
    "num_val = int(total_files * 0.2)\n",
    "num_test = total_files - num_train - num_val\n",
    "\n",
    "train_paths = all_file_paths[:num_train]\n",
    "val_paths = all_file_paths[num_train : num_train + num_val]\n",
    "test_paths = all_file_paths[num_train + num_val :]\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "class TipLevelDataset(Dataset):\n",
    "    def __init__(self, file_paths, feature_columns=['Fz'], target_column='Tip_Position', sampling_rate=100, fs=10000, cutoff=50):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self.feature_columns = feature_columns\n",
    "        self.target_column = target_column\n",
    "\n",
    "        for path in file_paths:\n",
    "            df = pd.read_csv(path)[feature_columns + [target_column]].dropna()\n",
    "\n",
    "            for col in feature_columns:\n",
    "                filtered = butter_lowpass_filter(df[col].values, cutoff=cutoff, fs=fs)\n",
    "                df[col] = (filtered - np.mean(filtered)) / np.std(filtered)\n",
    "\n",
    "            df_downsampled  = df.iloc[::100, :].copy()\n",
    "\n",
    "            input_tensor = torch.tensor(df_downsampled [feature_columns].values, dtype=torch.float32)  # shape: (seq_len, num_features)\n",
    "            target_tensor = torch.tensor(df_downsampled [target_column].values, dtype=torch.float32)   # shape: (seq_len,)\n",
    "\n",
    "            self.inputs.append(input_tensor)\n",
    "            self.targets.append(target_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.output_layer(lstm_out).squeeze(-1)\n",
    "        return output\n",
    "\n",
    "def train_lstm(model, train_dataset, val_dataset, epochs=300, lr=0.01):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for x_train, y_train in train_dataset:\n",
    "            x_train = x_train.unsqueeze(0).to(device)\n",
    "            y_train = y_train.unsqueeze(0).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_train)\n",
    "            loss = criterion(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        train_loss_history.append(total_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_dataset:\n",
    "                x_val = x_val.unsqueeze(0).to(device)\n",
    "                y_val = y_val.unsqueeze(0).to(device)\n",
    "                y_pred = model(x_val)\n",
    "                loss = criterion(y_pred, y_val)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        val_loss_history.append(total_val_loss)\n",
    "        scheduler.step(total_val_loss)\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            best_val_loss = total_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {total_train_loss:.4f}, Validation Loss = {total_val_loss:.4f} (Best model saved!)\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {total_train_loss:.4f}, Validation Loss = {total_val_loss:.4f}\")\n",
    "\n",
    "    return model, best_model_state, train_loss_history, val_loss_history\n",
    "\n",
    "def plot_learning_curve(train_loss, val_loss):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_critical_region(\n",
    "    model, test_dataset, feature_names=['Fz'], feature_list=None,\n",
    "    best_model_state=None, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), n_plot=5, center_threshold=-0, window=400\n",
    "):\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "\n",
    "    mae_total, rmse_total = 0, 0\n",
    "    count = 0 \n",
    "    all_maes = []\n",
    "\n",
    "    for i, (x, y_true) in enumerate(test_dataset):\n",
    "        with torch.no_grad():\n",
    "            x_input = x.unsqueeze(0).to(device)\n",
    "            y_pred = model(x_input)\n",
    "            y_pred = y_pred.squeeze(0).cpu().numpy()\n",
    "            x_np = x.numpy()\n",
    "            y_true_np = y_true.numpy()\n",
    "\n",
    "        idx_center = np.argmax(y_true_np >= center_threshold)\n",
    "        idx_start = idx_center - window\n",
    "        idx_end = idx_center + window\n",
    "\n",
    "        y_true_slice = y_true_np[idx_start:idx_end]\n",
    "        y_pred_slice = y_pred[idx_start:idx_end]\n",
    "        x_slice = x_np[idx_start:idx_end, :]\n",
    "\n",
    "        mae = mean_absolute_error(y_true_slice, y_pred_slice)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_slice, y_pred_slice))\n",
    "        all_maes.append(mae)\n",
    "        mae_total += mae\n",
    "        rmse_total += rmse\n",
    "        count += 1\n",
    "\n",
    "        if count <= n_plot:\n",
    "            plt.figure(figsize=(14, 6))\n",
    "\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(y_true_slice, label='True Tip_Position')\n",
    "            plt.plot(y_pred_slice, label='Predicted Tip_Position', linestyle='--')\n",
    "            plt.title(f\"Sample {i+1} Focused - MAE: {mae:.3f}, RMSE: {rmse:.3f}\")\n",
    "            plt.ylabel(\"Tip_Position\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            ax1 = plt.subplot(2, 1, 2)\n",
    "            for name in feature_names:\n",
    "                idx = feature_list.index(name)\n",
    "                ax1.plot(x_slice[:, idx], label=name, alpha=0.4)\n",
    "\n",
    "            ax1.set_ylabel(\"Input Features\")\n",
    "            plt.tight_layout()\n",
    "            plt.ylim(-3, 3)\n",
    "            plt.show()\n",
    "\n",
    "    focus_avg_mae = mae_total / count\n",
    "    focus_avg_rmse = rmse_total / count    \n",
    "\n",
    "    print(\"\\n=== Test Summary ===\")\n",
    "    print(f\"Average MAE  : {focus_avg_mae:.4f}\")\n",
    "    print(f\"Average RMSE : {focus_avg_rmse:.4f}\")\n",
    "\n",
    "    return all_maes, focus_avg_mae, focus_avg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6597de6f-41a4-4399-84e1-f4478cafe64f",
   "metadata": {},
   "source": [
    "# Thrust Force, Torque â†’ Tip_Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613257e7-3eb7-4c3f-b508-41c79aa0837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_zt = ['Fz', 'Torque']\n",
    "\n",
    "train_dataset_zt = TipLevelDataset(train_paths, feature_columns=feature_columns_zt)\n",
    "val_dataset_zt   = TipLevelDataset(val_paths, feature_columns=feature_columns_zt)\n",
    "test_dataset_zt  = TipLevelDataset(test_paths, feature_columns=feature_columns_zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427ca9e-f30b-4de5-9974-6fc430bf7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zt = LSTM(input_size=len(feature_columns_zt))\n",
    "\n",
    "model_zt, best_model_zt_state, train_loss_history_zt, val_loss_history_zt = train_lstm(\n",
    "    model_zt, train_dataset_zt, val_dataset_zt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cb956-2086-48be-a4f9-f1f0aa0f6aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(train_loss_history_zt, val_loss_history_zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24794f2-139c-4361-a593-5881f297c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_zt = ['Fz', 'Torque']\n",
    "\n",
    "zt_maes, critical_region_mae_zt, critical_region_rmse_zt = evaluate_critical_region(\n",
    "    model = model_zt,\n",
    "    test_dataset = test_dataset_zt,\n",
    "    feature_names=feature_columns_zt,\n",
    "    feature_list=feature_columns_zt,\n",
    "    best_model_state=best_model_zt_state,\n",
    "    n_plot=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b6239-6250-4a36-bab1-62503b9caa0a",
   "metadata": {},
   "source": [
    "# Thrust Force â†’ Tip_Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c929f-b0a9-42d2-83a2-e63820dd6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_z = ['Fz']\n",
    "\n",
    "train_dataset_z = TipLevelDataset(train_paths, feature_columns=feature_columns_z)\n",
    "val_dataset_z   = TipLevelDataset(val_paths, feature_columns=feature_columns_z)\n",
    "test_dataset_z  = TipLevelDataset(test_paths, feature_columns=feature_columns_z)\n",
    "\n",
    "model_z = LSTM(input_size=len(feature_columns_z))\n",
    "model_z, best_model_z_state, train_loss_history_z, val_loss_history_z = train_lstm(\n",
    "    model_z, train_dataset_z, val_dataset_z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d94225-7c05-482b-bb2d-9c0d242064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_loss_history_z, val_loss_history_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22774a-703a-49c3-b774-f64ab6e25ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_maes, critical_region_mae_z, critical_region_rmse_z = evaluate_critical_region(\n",
    "    model = model_z,\n",
    "    test_dataset = test_dataset_z,\n",
    "    feature_names=feature_columns_z,\n",
    "    feature_list=feature_columns_z,\n",
    "    best_model_state=best_model_z_state,\n",
    "    n_plot=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956e5fa-eef8-404d-9e48-fe3c5cb76833",
   "metadata": {},
   "source": [
    "# Torque â†’ Tip_Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727bd8e-fc73-4912-b9b4-09e8bd7eabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_T = ['Torque']\n",
    "\n",
    "train_dataset_T = TipLevelDataset(train_paths, feature_columns=feature_columns_T)\n",
    "val_dataset_T   = TipLevelDataset(val_paths, feature_columns=feature_columns_T)\n",
    "test_dataset_T  = TipLevelDataset(test_paths, feature_columns=feature_columns_T)\n",
    "\n",
    "model_T = LSTM(input_size=len(feature_columns_T))\n",
    "\n",
    "model_T, best_model_T_state, train_loss_history_T, val_loss_history_T = train_lstm(\n",
    "    model_T, train_dataset_T, val_dataset_T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532a66c-75be-4169-8379-9eef0a99fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_loss_history_T, val_loss_history_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887e89a-fb16-4a32-bd44-56e623d1db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_maes, critical_region_mae_t, critical_region_rmse_t = evaluate_critical_region(\n",
    "    model = model_T,\n",
    "    test_dataset = test_dataset_T,\n",
    "    feature_names=feature_columns_T,\n",
    "    feature_list=feature_columns_T,\n",
    "    best_model_state=best_model_T_state,\n",
    "    n_plot=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816793-eb43-43b0-bed0-db155eb0642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df = pd.DataFrame({'zt': zt_maes, 'z': z_maes, 't': t_maes})\n",
    "print(mae_df)\n",
    "filename = f\"mae_data.csv\"\n",
    "# mae_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbdde5-ca87-4c35-8c98-6d0f6093f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_data = ['Fz, Torque', 'Fz', 'Torque']\n",
    "mae = [critical_region_mae_zt, critical_region_mae_z, critical_region_mae_t]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(mae_data, mae, width=0.3, color='black')\n",
    "plt.ylim(0.2, 0.8)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Features\", fontsize=18)\n",
    "plt.ylabel(\"MAE\", fontsize=18)\n",
    "plt.title(\"comparison of MAE\", fontsize=20)\n",
    "\n",
    "for bar, value in zip(bars, mae):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.08, f\"{value:.3f}\",\n",
    "             ha='center', va='top', color=\"black\", fontsize=18)\n",
    "# plt.show()\n",
    "plt.savefig(\"MAE comparison\", dpi=330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e06bf-ba9f-4a2a-8858-7fd154a99e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
